# Minimal Perceptron on AND Gate 🧠

This is a barebones implementation of a single-layer Perceptron trained to learn the AND logic gate — the building block of neural networks.

### 📌 What's Inside

- Manual weight + bias initialization  
- Step activation function (classic style)  
- Perceptron learning rule (no frameworks!)  
- Trained on the AND gate truth table

### 📊 AND Gate Truth Table

| Input A | Input B | Output |
|---------|---------|--------|
|    0    |    0    |   0    |
|    0    |    1    |   0    |
|    1    |    0    |   0    |
|    1    |    1    |   1    |

### 🛠️ Run It Yourself

You can run this directly in **Google Colab**

This will print out trained weights, bias, and predictions for all inputs.
