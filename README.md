# Minimal Perceptron on AND Gate ğŸ§ 

This is a barebones implementation of a single-layer Perceptron trained to learn the AND logic gate â€” the building block of neural networks.

### ğŸ“Œ What's Inside

- Manual weight + bias initialization  
- Step activation function (classic style)  
- Perceptron learning rule (no frameworks!)  
- Trained on the AND gate truth table

### ğŸ“Š AND Gate Truth Table

| Input A | Input B | Output |
|---------|---------|--------|
|    0    |    0    |   0    |
|    0    |    1    |   0    |
|    1    |    0    |   0    |
|    1    |    1    |   1    |

### ğŸ› ï¸ Run It Yourself

You can run this directly in **Google Colab**

This will print out trained weights, bias, and predictions for all inputs.
